{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning Yolov11m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.67 🚀 Python-3.10.12 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1060 3GB, 3004MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11l.pt, data=/home/joey/Projects/chatbrain/backend/vision_model/chat_dataset.yaml, epochs=100, time=9, patience=10, batch=4, imgsz=640, save=True, save_period=-1, cache=True, device=0, workers=8, project=None, name=train17, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=15, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.5, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/joey/Projects/chatbrain/runs/detect/train17\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1413337  ultralytics.nn.modules.head.Detect           [3, [256, 512, 512]]          \n",
      "YOLO11l summary: 631 layers, 25,312,793 parameters, 25,312,777 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.2.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.2.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.2.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.2.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.4.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.4.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.6.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.8.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.8.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.8.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.10.cv1.conv.weight'\n",
      "Freezing layer 'model.10.cv1.bn.weight'\n",
      "Freezing layer 'model.10.cv1.bn.bias'\n",
      "Freezing layer 'model.10.cv2.conv.weight'\n",
      "Freezing layer 'model.10.cv2.bn.weight'\n",
      "Freezing layer 'model.10.cv2.bn.bias'\n",
      "Freezing layer 'model.10.m.0.attn.qkv.conv.weight'\n",
      "Freezing layer 'model.10.m.0.attn.qkv.bn.weight'\n",
      "Freezing layer 'model.10.m.0.attn.qkv.bn.bias'\n",
      "Freezing layer 'model.10.m.0.attn.proj.conv.weight'\n",
      "Freezing layer 'model.10.m.0.attn.proj.bn.weight'\n",
      "Freezing layer 'model.10.m.0.attn.proj.bn.bias'\n",
      "Freezing layer 'model.10.m.0.attn.pe.conv.weight'\n",
      "Freezing layer 'model.10.m.0.attn.pe.bn.weight'\n",
      "Freezing layer 'model.10.m.0.attn.pe.bn.bias'\n",
      "Freezing layer 'model.10.m.0.ffn.0.conv.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.0.bn.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.0.bn.bias'\n",
      "Freezing layer 'model.10.m.0.ffn.1.conv.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.1.bn.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.1.bn.bias'\n",
      "Freezing layer 'model.10.m.1.attn.qkv.conv.weight'\n",
      "Freezing layer 'model.10.m.1.attn.qkv.bn.weight'\n",
      "Freezing layer 'model.10.m.1.attn.qkv.bn.bias'\n",
      "Freezing layer 'model.10.m.1.attn.proj.conv.weight'\n",
      "Freezing layer 'model.10.m.1.attn.proj.bn.weight'\n",
      "Freezing layer 'model.10.m.1.attn.proj.bn.bias'\n",
      "Freezing layer 'model.10.m.1.attn.pe.conv.weight'\n",
      "Freezing layer 'model.10.m.1.attn.pe.bn.weight'\n",
      "Freezing layer 'model.10.m.1.attn.pe.bn.bias'\n",
      "Freezing layer 'model.10.m.1.ffn.0.conv.weight'\n",
      "Freezing layer 'model.10.m.1.ffn.0.bn.weight'\n",
      "Freezing layer 'model.10.m.1.ffn.0.bn.bias'\n",
      "Freezing layer 'model.10.m.1.ffn.1.conv.weight'\n",
      "Freezing layer 'model.10.m.1.ffn.1.bn.weight'\n",
      "Freezing layer 'model.10.m.1.ffn.1.bn.bias'\n",
      "Freezing layer 'model.13.cv1.conv.weight'\n",
      "Freezing layer 'model.13.cv1.bn.weight'\n",
      "Freezing layer 'model.13.cv1.bn.bias'\n",
      "Freezing layer 'model.13.cv2.conv.weight'\n",
      "Freezing layer 'model.13.cv2.bn.weight'\n",
      "Freezing layer 'model.13.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.13.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.13.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.13.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.1.cv3.conv.weight'\n",
      "Freezing layer 'model.13.m.1.cv3.bn.weight'\n",
      "Freezing layer 'model.13.m.1.cv3.bn.bias'\n",
      "Freezing layer 'model.13.m.1.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.1.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.1.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.1.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.1.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.1.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.1.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.1.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.1.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.1.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.1.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.1.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/labels.cache... 309 images, 46 backgrounds, 0 corrupt: 100%|██████████| 309/309 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/1000012010.JPEG: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/1000012151.JPEG: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/1000012195.JPEG: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.2GB RAM): 100%|██████████| 309/309 [00:01<00:00, 187.46it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/joey/Projects/chatbrain/backend/vision_model/dataset/val/labels.cache... 78 images, 16 backgrounds, 0 corrupt: 100%|██████████| 78/78 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/val/images/1000012074.JPEG: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/val/images/1000012188.JPEG: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100%|██████████| 78/78 [00:00<00:00, 157.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/joey/Projects/chatbrain/runs/detect/train17/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 6 dataloader workers\n",
      "Logging results to \u001b[1m/home/joey/Projects/chatbrain/runs/detect/train17\u001b[0m\n",
      "Starting training for 9 hours...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      1.75G      2.075      2.609      1.497         70        640:  26%|██▌       | 20/78 [00:18<00:54,  1.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(yaml_path), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/train/images\u001b[39m\u001b[38;5;124m\"\u001b[39m)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain images missing!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(yaml_path), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/val/images\u001b[39m\u001b[38;5;124m\"\u001b[39m)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal images missing!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myaml_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# maxium training time in hours\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# early stopping patience\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Must reduce batch size dramatically\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Freeze first 15 layers\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmosaic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reduce augmentation memory usage\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# image size\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# cache images for faster training\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/chatbrain/.venv/lib/python3.10/site-packages/ultralytics/engine/model.py:806\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 806\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/Projects/chatbrain/.venv/lib/python3.10/site-packages/ultralytics/engine/trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/chatbrain/.venv/lib/python3.10/site-packages/ultralytics/engine/trainer.py:380\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[1;32m    379\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m world_size\n",
      "File \u001b[0;32m~/Projects/chatbrain/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/chatbrain/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Projects/chatbrain/.venv/lib/python3.10/site-packages/ultralytics/nn/tasks.py:109\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Projects/chatbrain/.venv/lib/python3.10/site-packages/ultralytics/nn/tasks.py:291\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[1;32m    290\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/chatbrain/.venv/lib/python3.10/site-packages/ultralytics/utils/loss.py:219\u001b[0m, in \u001b[0;36mv8DetectionLoss.__call__\u001b[0;34m(self, preds, batch)\u001b[0m\n\u001b[1;32m    217\u001b[0m dtype \u001b[38;5;241m=\u001b[39m pred_scores\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    218\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m pred_scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 219\u001b[0m imgsz \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# image size (h,w)\u001b[39;00m\n\u001b[1;32m    220\u001b[0m anchor_points, stride_tensor \u001b[38;5;241m=\u001b[39m make_anchors(feats, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Targets\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# load the pretrained medium model\n",
    "model = YOLO(\"yolo11l.pt\")\n",
    "\n",
    "# Use absolute path to YAML\n",
    "yaml_path = \"/home/joey/Projects/chatbrain/backend/vision_model/chat_dataset.yaml\"\n",
    "\n",
    "# Verify paths\n",
    "assert os.path.exists(yaml_path), \"YAML file not found!\"\n",
    "assert os.path.exists(os.path.join(os.path.dirname(yaml_path), \"dataset/train/images\")), \"Train images missing!\"\n",
    "assert os.path.exists(os.path.join(os.path.dirname(yaml_path), \"dataset/val/images\")), \"Val images missing!\"\n",
    "\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=100,\n",
    "    time=9, # maxium training time in hours\n",
    "    device=\"0\",\n",
    "    patience=10, # early stopping patience\n",
    "    batch=4,  # Must reduce batch size dramatically\n",
    "    multi_scale=False,\n",
    "    freeze=15,  # Freeze first 15 layers\n",
    "    mosaic=0.5,  # Reduce augmentation memory usage\n",
    "    imgsz=640, # image size\n",
    "    cache=True, # cache images for faster training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort detected boxes vertically to get message order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(results):\n",
    "    boxes = []\n",
    "    for box in results[0].boxes:\n",
    "        cls = int(box.cls)\n",
    "        coords = box.xyxy[0].tolist()  # [ax, ay, bx, by]\n",
    "        boxes.append((cls, coords))\n",
    "    \n",
    "    # Sort non-contact boxes by Y-coordinate (ay)\n",
    "    contact_boxes = [b for b in boxes if b[0] == 0]\n",
    "    message_boxes = sorted(\n",
    "        [b for b in boxes if b[0] != 0],\n",
    "        key=lambda x: x[1][1]  # Sort by ay (top Y-coordinate)\n",
    "    )\n",
    "    \n",
    "    # Assign 'num' (0 for contacts, 1,2,3... for messages)\n",
    "    final = []\n",
    "    for cls, (ax, ay, bx, by) in contact_boxes:\n",
    "        final.append([ax, ay, bx, by, 0, 0])  # Type 0, num=0\n",
    "    \n",
    "    for i, (cls, (ax, ay, bx, by)) in enumerate(message_boxes, 1):\n",
    "        final.append([ax, ay, bx, by, cls, i])  # Type 1/2, num=i\n",
    "    \n",
    "    return final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
