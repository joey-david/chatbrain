{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning Yolov11m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.67 🚀 Python-3.10.12 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1060 3GB, 3004MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11l.pt, data=/home/joey/Projects/chatbrain/backend/vision_model/chat_dataset.yaml, epochs=100, time=0.05, patience=10, batch=-1, imgsz=640, save=True, save_period=-1, cache=True, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/joey/Projects/chatbrain/runs/detect/train3\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/home/joey/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 18.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1413337  ultralytics.nn.modules.head.Detect           [3, [256, 512, 512]]          \n",
      "YOLO11l summary: 631 layers, 25,312,793 parameters, 25,312,777 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 44.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/labels... 29 images, 4 backgrounds, 6 corrupt: 100%|██████████| 29/29 [00:00<00:00, 282.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/IMG_1192.PNG: ignoring corrupt image/label: negative label values [-0.014243]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/IMG_1345.PNG: ignoring corrupt image/label: negative label values [-0.361333]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/IMG_1415.PNG: ignoring corrupt image/label: negative label values [-0.015742 -0.308   ]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/IMG_1536.PNG: ignoring corrupt image/label: negative label values [-0.012744]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/i-think-i-got-the-job-guys-v0-77de6w1gzdde1.webp: ignoring corrupt image/label: negative label values [-0.110078]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/scammy-sammy-part-3-v0-boypq8chzkde1.webp: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.034005 1.020896 1.107463]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB RAM): 100%|██████████| 23/23 [00:00<00:00, 207.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce GTX 1060 3GB) 2.93G total, 0.25G reserved, 0.23G allocated, 2.46G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    25312793       87.28         1.363         97.12         163.5        (1, 3, 640, 640)                    list\n",
      "    25312793       174.6         2.038         141.2         252.9        (2, 3, 640, 640)                    list\n",
      "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 2.93 GiB of which 74.44 MiB is free. Including non-PyTorch memory, this process has 1.95 GiB memory in use. Of the allocated memory 1.76 GiB is allocated by PyTorch, and 57.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 2.93 GiB of which 69.38 MiB is free. Including non-PyTorch memory, this process has 1.96 GiB memory in use. Of the allocated memory 1.75 GiB is allocated by PyTorch, and 84.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 2.93 GiB of which 71.62 MiB is free. Including non-PyTorch memory, this process has 1.96 GiB memory in use. Of the allocated memory 1.80 GiB is allocated by PyTorch, and 37.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 1 for CUDA:0 1.84G/2.93G (63%) ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/labels.cache... 29 images, 4 backgrounds, 6 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/IMG_1192.PNG: ignoring corrupt image/label: negative label values [-0.014243]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/IMG_1345.PNG: ignoring corrupt image/label: negative label values [-0.361333]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/IMG_1415.PNG: ignoring corrupt image/label: negative label values [-0.015742 -0.308   ]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/IMG_1536.PNG: ignoring corrupt image/label: negative label values [-0.012744]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/i-think-i-got-the-job-guys-v0-77de6w1gzdde1.webp: ignoring corrupt image/label: negative label values [-0.110078]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/train/images/scammy-sammy-part-3-v0-boypq8chzkde1.webp: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.034005 1.020896 1.107463]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB RAM): 100%|██████████| 23/23 [00:00<00:00, 230.59it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/joey/Projects/chatbrain/backend/vision_model/dataset/val/labels... 8 images, 2 backgrounds, 2 corrupt: 100%|██████████| 8/8 [00:00<00:00, 195.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/val/images/IMG_1540.PNG: ignoring corrupt image/label: negative label values [-0.010495]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/joey/Projects/chatbrain/backend/vision_model/dataset/val/images/com.imessage.text.ios--33-screenshot2.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.050847 1.084746 1.118644]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/joey/Projects/chatbrain/backend/vision_model/dataset/val/labels.cache\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM): 100%|██████████| 6/6 [00:00<00:00, 64.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/joey/Projects/chatbrain/runs/detect/train3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 6 dataloader workers\n",
      "Logging results to \u001b[1m/home/joey/Projects/chatbrain/runs/detect/train3\u001b[0m\n",
      "Starting training for 0.05 hours...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      1.77G      4.316      5.983       2.81          0        416: 100%|██████████| 23/23 [00:11<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/14      1.85G       4.27       6.93        2.9         11        800: 100%|██████████| 23/23 [00:11<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/15      1.96G      4.603      5.512      3.059         25        640: 100%|██████████| 23/23 [00:09<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/15       1.9G      4.555      6.605      2.991         23        960: 100%|██████████| 23/23 [00:10<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/16      1.52G      4.438      6.088      2.771         25        352: 100%|██████████| 23/23 [00:10<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/16      1.88G      4.873      6.073      3.082          3        576: 100%|██████████| 23/23 [00:09<00:00,  2.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/16      1.89G      3.651      7.608      2.795         14        672: 100%|██████████| 23/23 [00:11<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/16      1.94G       3.94      7.921      2.675          5        608: 100%|██████████| 23/23 [00:11<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/16      1.97G      3.697      6.723      2.632          5        768: 100%|██████████| 23/23 [00:12<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41   0.000483     0.0185   0.000268   2.68e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/15      1.93G      4.295      7.353      2.962          8        704: 100%|██████████| 23/23 [00:11<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41   0.000483     0.0185   0.000268   2.68e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/15      1.95G      3.897      7.045      2.655         10        320: 100%|██████████| 23/23 [00:10<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41   0.000501     0.0175   0.000278   2.78e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/16      1.97G      3.801      7.126      2.587          0        352: 100%|██████████| 23/23 [00:09<00:00,  2.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41   0.000501     0.0175   0.000278   2.78e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/16      1.79G      3.786      7.386      2.736          0        640: 100%|██████████| 23/23 [00:09<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41   0.000501     0.0175   0.000278   2.78e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/16      1.78G      3.922      6.641        2.7          8        704: 100%|██████████| 23/23 [00:08<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41   0.000518     0.0175   0.000284   2.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/16      1.97G      3.933      7.879       2.64         14        704: 100%|██████████| 23/23 [00:09<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41   0.000518     0.0175   0.000284   2.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/16      1.76G      3.972      6.135      2.762          0        576: 100%|██████████| 23/23 [00:09<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41   0.000518     0.0175   0.000284   2.84e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from /home/joey/Projects/chatbrain/runs/detect/train3/weights/last.pt, 51.2MB\n",
      "Optimizer stripped from /home/joey/Projects/chatbrain/runs/detect/train3/weights/best.pt, 51.2MB\n",
      "\n",
      "Validating /home/joey/Projects/chatbrain/runs/detect/train3/weights/best.pt...\n",
      "Ultralytics 8.3.67 🚀 Python-3.10.12 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1060 3GB, 3004MiB)\n",
      "YOLO11l summary (fused): 464 layers, 25,281,625 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          6         41   0.000513     0.0175   0.000281   2.81e-05\n",
      "          contact_name          4         19    0.00154     0.0526   0.000842   8.42e-05\n",
      "               own_msg          4         18          0          0          0          0\n",
      "            others_msg          4          4          0          0          0          0\n",
      "Speed: 1.0ms preprocess, 57.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1m/home/joey/Projects/chatbrain/runs/detect/train3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# load the pretrained medium model\n",
    "model = YOLO(\"yolo11l.pt\")\n",
    "\n",
    "# Use absolute path to YAML\n",
    "yaml_path = \"/home/joey/Projects/chatbrain/backend/vision_model/chat_dataset.yaml\"\n",
    "\n",
    "# Verify paths\n",
    "assert os.path.exists(yaml_path), \"YAML file not found!\"\n",
    "assert os.path.exists(os.path.join(os.path.dirname(yaml_path), \"dataset/train/images\")), \"Train images missing!\"\n",
    "assert os.path.exists(os.path.join(os.path.dirname(yaml_path), \"dataset/val/images\")), \"Val images missing!\"\n",
    "\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=100,\n",
    "    time=0.05, # maxium training time in hours\n",
    "    patience=10, # early stopping patience\n",
    "    batch=-1, # auto batch size\n",
    "    imgsz=640, # image size\n",
    "    multi_scale=True,  # Vary imgsz ±50% during training\n",
    "    cache=True, # cache images for faster training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort detected boxes vertically to get message order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(results):\n",
    "    boxes = []\n",
    "    for box in results[0].boxes:\n",
    "        cls = int(box.cls)\n",
    "        coords = box.xyxy[0].tolist()  # [ax, ay, bx, by]\n",
    "        boxes.append((cls, coords))\n",
    "    \n",
    "    # Sort non-contact boxes by Y-coordinate (ay)\n",
    "    contact_boxes = [b for b in boxes if b[0] == 0]\n",
    "    message_boxes = sorted(\n",
    "        [b for b in boxes if b[0] != 0],\n",
    "        key=lambda x: x[1][1]  # Sort by ay (top Y-coordinate)\n",
    "    )\n",
    "    \n",
    "    # Assign 'num' (0 for contacts, 1,2,3... for messages)\n",
    "    final = []\n",
    "    for cls, (ax, ay, bx, by) in contact_boxes:\n",
    "        final.append([ax, ay, bx, by, 0, 0])  # Type 0, num=0\n",
    "    \n",
    "    for i, (cls, (ax, ay, bx, by)) in enumerate(message_boxes, 1):\n",
    "        final.append([ax, ay, bx, by, cls, i])  # Type 1/2, num=i\n",
    "    \n",
    "    return final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
